import os
import yaml
import shutil
from PIL import Image
import cv2
import numpy as np
from pathlib import Path

def resize_image_with_padding(image, target_size):
    """
    Resize image to target size while maintaining aspect ratio and padding with black.
    Works for both upscaling (small images) and downscaling (large images).
    Returns resized image and transformation parameters.
    """
    target_width, target_height = target_size
    orig_height, orig_width = image.shape[:2]
    
    # Calculate scale factor to fit image within target size
    scale = min(target_width / orig_width, target_height / orig_height)
    
    # Calculate new dimensions
    new_width = int(orig_width * scale)
    new_height = int(orig_height * scale)
    
    # Resize image (works for both upscaling and downscaling)
    resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
    
    # Create padded image with black background
    padded = np.zeros((target_height, target_width, 3), dtype=np.uint8)
    
    # Calculate padding offsets (center the image)
    x_offset = (target_width - new_width) // 2
    y_offset = (target_height - new_height) // 2
    
    # Place resized image in center
    padded[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized
    
    # Return padded image and transformation info
    transform_info = {
        'scale': scale,
        'x_offset': x_offset,
        'y_offset': y_offset,
        'new_width': new_width,
        'new_height': new_height
    }
    
    return padded, transform_info

def transform_yolo_annotations(annotations, transform_info, target_size):
    """
    Transform YOLO annotations to account for padding and resizing.
    YOLO format: [class_id, x_center, y_center, width, height] (all normalized 0-1)
    """
    transformed_annotations = []
    target_width, target_height = target_size
    
    for ann in annotations:
        class_id, x_center, y_center, width, height = ann
        
        # Scale coordinates to padded image dimensions
        # Original coordinates are normalized (0-1), so we need to:
        # 1. Scale them to the resized (but not padded) dimensions
        # 2. Add the offset from padding
        # 3. Normalize back to 0-1 for the target size
        
        # Convert to pixel coordinates in resized image
        x_pixel = x_center * transform_info['new_width']
        y_pixel = y_center * transform_info['new_height']
        w_pixel = width * transform_info['new_width']
        h_pixel = height * transform_info['new_height']
        
        # Add padding offset
        x_pixel += transform_info['x_offset']
        y_pixel += transform_info['y_offset']
        
        # Convert back to normalized coordinates for target size
        x_norm = x_pixel / target_width
        y_norm = y_pixel / target_height
        w_norm = w_pixel / target_width
        h_norm = h_pixel / target_height
        
        # Ensure coordinates are within bounds
        x_norm = max(0.0, min(1.0, x_norm))
        y_norm = max(0.0, min(1.0, y_norm))
        w_norm = max(0.001, min(1.0, w_norm))
        h_norm = max(0.001, min(1.0, h_norm))
        
        transformed_annotations.append([class_id, x_norm, y_norm, w_norm, h_norm])
    
    return transformed_annotations

def validate_and_fix_szarvas_label(label_file):
    """Validate YOLO format label file and map all classes to deer (class 7)"""
    annotations = []
    
    try:
        with open(label_file, 'r') as f:
            lines = f.readlines()
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            parts = line.split()
            if len(parts) >= 5:
                try:
                    # YOLO format: class_id x_center y_center width height
                    original_class_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    
                    # Map to our deer class (class 7)
                    # Since this is szarvas (deer) dataset, all detections should be deer
                    unified_class_id = 7  # All szarvas ‚Üí deer
                    
                    # Validate coordinates are in [0,1] range
                    if (0 <= x_center <= 1 and 0 <= y_center <= 1 and 
                        0 < width <= 1 and 0 < height <= 1):
                        annotations.append([unified_class_id, x_center, y_center, width, height])
                    else:
                        print(f"Warning: Invalid coordinates in line: {line}")
                    
                except ValueError:
                    print(f"Warning: Could not parse line: {line}")
                    continue
    
    except Exception as e:
        print(f"Warning: Error reading label file {label_file}: {e}")
    
    return annotations

def process_szarvas_split_CORRECTED(szarvas_base_path, output_base_path, split_name, target_size=(640, 512)):
    """CORRECTED: Process Szarvas data with aspect ratio preservation"""
    
    # Map valid to val for consistency
    output_split = 'val' if split_name == 'valid' else split_name
    
    split_path = os.path.join(szarvas_base_path, split_name)
    if not os.path.exists(split_path):
        print(f"Warning: Split {split_name} not found at {split_path}")
        return
    
    images_path = os.path.join(split_path, 'images')
    labels_path = os.path.join(split_path, 'labels')
    
    if not os.path.exists(images_path):
        print(f"Warning: Images folder not found at {images_path}")
        return
    
    if not os.path.exists(labels_path):
        print(f"Warning: Labels folder not found at {labels_path}")
        return
    
    print(f"Processing Szarvas {split_name} split...")
    
    # Output paths - add to existing main_dataset
    output_images_path = os.path.join(output_base_path, 'main_dataset', output_split, 'images')
    output_labels_path = os.path.join(output_base_path, 'main_dataset', output_split, 'labels')
    
    # Ensure directories exist
    os.makedirs(output_images_path, exist_ok=True)
    os.makedirs(output_labels_path, exist_ok=True)
    
    # Get all images
    image_files = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    processed_count = 0
    skipped_count = 0
    coordinate_errors = 0
    size_stats = {'smaller': 0, 'larger': 0, 'exact': 0}
    
    for image_filename in image_files:
        image_path = os.path.join(images_path, image_filename)
        
        # Find corresponding label file
        base_name = os.path.splitext(image_filename)[0]
        label_file = os.path.join(labels_path, base_name + '.txt')
        
        if not os.path.exists(label_file):
            print(f"Warning: No label found for {image_filename}")
            skipped_count += 1
            continue
        
        # Load original image
        original_image = cv2.imread(image_path)
        if original_image is None:
            print(f"Warning: Could not load image {image_path}")
            skipped_count += 1
            continue
        
        # Track image size relative to target
        orig_h, orig_w = original_image.shape[:2]
        if orig_w < target_size[0] or orig_h < target_size[1]:
            size_stats['smaller'] += 1
        elif orig_w > target_size[0] or orig_h > target_size[1]:
            size_stats['larger'] += 1
        else:
            size_stats['exact'] += 1
        
        # Resize image with padding to maintain aspect ratio
        padded_image, transform_info = resize_image_with_padding(original_image, target_size)
        
        # Create unique filename
        clean_filename = os.path.basename(image_filename)
        base_name = os.path.splitext(clean_filename)[0]
        extension = os.path.splitext(clean_filename)[1]
        unique_filename = f"szarvas_{output_split}_{base_name}{extension}"
        
        # Save padded image
        output_image_path = os.path.join(output_images_path, unique_filename)
        cv2.imwrite(output_image_path, padded_image)
        
        # Parse and validate existing YOLO annotations
        original_annotations = validate_and_fix_szarvas_label(label_file)
        
        # Transform annotations to account for padding
        transformed_annotations = transform_yolo_annotations(original_annotations, transform_info, target_size)
        
        if not transformed_annotations:
            coordinate_errors += 1
        
        # Save YOLO format label file with transformed coordinates
        label_filename = os.path.splitext(unique_filename)[0] + '.txt'
        label_path = os.path.join(output_labels_path, label_filename)
        
        with open(label_path, 'w') as f:
            for annotation in transformed_annotations:
                class_id, x_center, y_center, width, height = annotation
                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
        
        processed_count += 1
        if processed_count % 50 == 0:
            print(f"  Processed {processed_count} images...")
    
    print(f"  Completed Szarvas {split_name}: {processed_count} images processed, {skipped_count} skipped")
    print(f"  Image sizes: {size_stats['smaller']} smaller, {size_stats['larger']} larger, {size_stats['exact']} exact match")
    if coordinate_errors > 0:
        print(f"  Files with no valid annotations: {coordinate_errors}")

def validate_szarvas_annotations(base_path, num_samples=5):
    """Validate Szarvas annotations to ensure they look correct"""
    print(f"\nüîç VALIDATING SZARVAS ANNOTATIONS")
    print("=" * 50)
    
    train_labels_path = os.path.join(base_path, 'main_dataset', 'train', 'labels')
    if not os.path.exists(train_labels_path):
        print("No training labels found for validation")
        return
    
    # Look specifically for Szarvas files
    szarvas_files = [f for f in os.listdir(train_labels_path) if f.startswith('szarvas_')][:num_samples]
    
    if not szarvas_files:
        print("No Szarvas files found for validation")
        return
    
    for label_file in szarvas_files:
        label_path = os.path.join(train_labels_path, label_file)
        print(f"\nüìÑ {label_file}:")
        
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
            
            valid_count = 0
            invalid_count = 0
            class_distribution = {}
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    try:
                        class_id = int(parts[0])
                        x, y, w, h = map(float, parts[1:5])
                        
                        # Track class distribution
                        class_distribution[class_id] = class_distribution.get(class_id, 0) + 1
                        
                        # Check if coordinates are in valid range
                        if (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):
                            valid_count += 1
                        else:
                            invalid_count += 1
                            print(f"   ‚ö†Ô∏è  Invalid: class={class_id}, x={x:.3f}, y={y:.3f}, w={w:.3f}, h={h:.3f}")
                    except ValueError:
                        invalid_count += 1
            
            print(f"   ‚úÖ Valid annotations: {valid_count}")
            print(f"   ü¶å Classes found: {class_distribution} (should be class 7 = deer)")
            if invalid_count > 0:
                print(f"   ‚ùå Invalid annotations: {invalid_count}")
            else:
                print(f"   üéØ All Szarvas coordinates properly normalized!")
                
        except Exception as e:
            print(f"   Error reading file: {e}")

def count_combined_deer_data(base_path):
    """Count combined deer data from both Roe deer and Szarvas"""
    print(f"\nüìä COMBINED DEER DETECTION SUMMARY")
    print("=" * 50)
    
    train_labels_path = os.path.join(base_path, 'main_dataset', 'train', 'labels')
    if not os.path.exists(train_labels_path):
        print("No training labels found")
        return
    
    deer_sources = {
        'roe_deer': 0,
        'szarvas': 0
    }
    
    total_deer_annotations = 0
    
    for label_file in os.listdir(train_labels_path):
        if label_file.startswith('roe_deer_') or label_file.startswith('szarvas_'):
            label_path = os.path.join(train_labels_path, label_file)
            
            try:
                with open(label_path, 'r') as f:
                    lines = f.readlines()
                
                deer_count = 0
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        if class_id == 7:  # deer class
                            deer_count += 1
                            total_deer_annotations += 1
                
                # Track by source
                if label_file.startswith('roe_deer_'):
                    deer_sources['roe_deer'] += deer_count
                elif label_file.startswith('szarvas_'):
                    deer_sources['szarvas'] += deer_count
                    
            except Exception:
                continue
    
    print(f"ü¶å Total deer annotations: {total_deer_annotations}")
    print(f"   From Roe deer dataset: {deer_sources['roe_deer']}")
    print(f"   From Szarvas dataset: {deer_sources['szarvas']}")
    print(f"üéØ Combined deer detection capability: STRONG!")

def main():
    # Set paths
    base_path = r"D:\datasets"
    szarvas_path = os.path.join(base_path, "szarvas.v7i.yolov11")
    
    # Verify Szarvas dataset exists
    if not os.path.exists(szarvas_path):
        print(f"Error: Szarvas dataset not found at {szarvas_path}")
        return
    
    print("üöÄ STARTING SZARVAS PREPROCESSING (MORE DEER)")
    print("=" * 60)
    print(f"Source: {szarvas_path}")
    print(f"Output: Adding to existing main_dataset")
    print("üñºÔ∏è IMAGE PROCESSING: Aspect ratio preserved with black padding")
    print("ü¶å SZARVAS: Hungarian deer dataset ‚Üí class 7 (deer)")
    print("‚úÖ HANDLES: Both smaller and larger images than 640x512")
    print("üéØ COMBINING: With Roe deer for robust deer detection")
    print("=" * 60)
    
    # Check if main_dataset exists
    main_dataset_path = os.path.join(base_path, 'main_dataset')
    if not os.path.exists(main_dataset_path):
        print("Warning: main_dataset folder doesn't exist. Run thermal datasets first.")
        return
    
    # Check if deer class already exists (should be added by Roe deer script)
    yaml_path = os.path.join(main_dataset_path, 'data.yaml')
    if os.path.exists(yaml_path):
        try:
            with open(yaml_path, 'r') as f:
                content = f.read()
            if 'deer' not in content:
                print("Warning: 'deer' class not found in data.yaml. Run Roe deer preprocessing first.")
                return
            else:
                print("‚úÖ Found existing 'deer' class in data.yaml - good!")
        except Exception as e:
            print(f"Warning: Could not read data.yaml: {e}")
    
    # Process train, valid, and test splits
    splits = ['train', 'valid', 'test']
    for split in splits:
        process_szarvas_split_CORRECTED(szarvas_path, base_path, split, target_size=(640, 512))
    
    # Validate sample annotations
    validate_szarvas_annotations(base_path)
    
    # Count combined deer data
    count_combined_deer_data(base_path)
    
    print("\n‚úÖ SZARVAS preprocessing completed!")
    print("üìä Summary:")
    print("   - Hungarian deer data added to strengthen deer detection")
    print("   - All szarvas mapped to class 7 (same as roe deer)")
    print("   - Aspect ratio preserved with black padding")
    print("   - Annotations correctly transformed for padded images")
    print("   - Works for both upscaling and downscaling")
    print("   - Combined with Roe deer for robust wildlife detection")
    print("   - Images resized to 640x512 for FLIR ADK compatibility")
    print("\nü¶å DEER DETECTION: SIGNIFICANTLY ENHANCED!")
    print("Ready for final wildlife dataset (My Game Pics - multi-species)!")

if __name__ == "__main__":
    main()
