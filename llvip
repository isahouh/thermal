import os
import xml.etree.ElementTree as ET
import shutil
from PIL import Image
import cv2
import numpy as np
from pathlib import Path
import glob

def parse_llvip_xml_CORRECTED(xml_file):
    """CORRECTED: Parse LLVIP XML annotation (Pascal VOC format) with robust error handling"""
    try:
        tree = ET.parse(xml_file)
        root = tree.getroot()
        
        # Get image info
        filename = ""
        filename_elem = root.find('filename')
        if filename_elem is not None and filename_elem.text:
            filename = filename_elem.text
        
        # Get image dimensions
        width = height = 0
        size = root.find('size')
        if size is not None:
            width_elem = size.find('width')
            height_elem = size.find('height')
            if width_elem is not None and width_elem.text:
                width = int(float(width_elem.text))
            if height_elem is not None and height_elem.text:
                height = int(float(height_elem.text))
        
        # Get objects
        objects = []
        for obj in root.findall('object'):
            try:
                # Get object name/class
                name_elem = obj.find('name')
                if name_elem is None or not name_elem.text:
                    continue
                name = name_elem.text
                
                # Get bounding box
                bbox = obj.find('bndbox')
                if bbox is None:
                    continue
                
                xmin_elem = bbox.find('xmin')
                ymin_elem = bbox.find('ymin') 
                xmax_elem = bbox.find('xmax')
                ymax_elem = bbox.find('ymax')
                
                if not all(elem is not None and elem.text for elem in [xmin_elem, ymin_elem, xmax_elem, ymax_elem]):
                    continue
                
                xmin = int(float(xmin_elem.text))
                ymin = int(float(ymin_elem.text))
                xmax = int(float(xmax_elem.text))
                ymax = int(float(ymax_elem.text))
                
                # Validate bbox
                if xmax > xmin and ymax > ymin:
                    objects.append({
                        'name': name,
                        'bbox': [xmin, ymin, xmax, ymax]
                    })
                    
            except Exception as e:
                print(f"Warning: Error parsing object in {xml_file}: {e}")
                continue
        
        return filename, width, height, objects
        
    except Exception as e:
        print(f"Error parsing XML file {xml_file}: {e}")
        return "", 0, 0, []

def get_llvip_class_mapping():
    """Map LLVIP classes to our unified YOLO classes"""
    llvip_to_yolo_classes = {
        'person': 0,
        'people': 0,
        'pedestrian': 0,
        'human': 0,
        'man': 0,
        'woman': 0,
        'child': 0,
        'bicycle': 1,
        'bike': 1,
        'car': 2,
        'vehicle': 2,
        'motorcycle': 3,
        'bus': 4,
        'truck': 5,
    }
    
    return llvip_to_yolo_classes

def voc_to_yolo_bbox_CORRECTED(voc_bbox, original_img_width, original_img_height):
    """
    CORRECTED: Convert Pascal VOC bbox [xmin, ymin, xmax, ymax] to YOLO format 
    [x_center, y_center, width, height] normalized using ORIGINAL image dimensions
    """
    xmin, ymin, xmax, ymax = voc_bbox
    
    # Calculate center and dimensions
    x_center = (xmin + xmax) / 2
    y_center = (ymin + ymax) / 2
    width = xmax - xmin
    height = ymax - ymin
    
    # Normalize by ORIGINAL image dimensions (CRITICAL!)
    x_center /= original_img_width
    y_center /= original_img_height
    width /= original_img_width
    height /= original_img_height
    
    # Clamp to valid range [0, 1]
    x_center = max(0.0, min(1.0, x_center))
    y_center = max(0.0, min(1.0, y_center))
    width = max(0.001, min(1.0, width))
    height = max(0.001, min(1.0, height))
    
    return [x_center, y_center, width, height]

def process_llvip_split_CORRECTED(llvip_base_path, output_base_path, split_name, target_size=(640, 512)):
    """CORRECTED: Process LLVIP data with proper bbox normalization"""
    
    # Path to inner LLVIP folder
    inner_llvip = os.path.join(llvip_base_path, 'LLVIP')
    if not os.path.exists(inner_llvip):
        print(f"Error: Inner LLVIP folder not found at {inner_llvip}")
        return
    
    # Use infrared images (thermal) - prioritize over visible
    ir_images_path = os.path.join(inner_llvip, 'infrared', split_name)
    annotations_path = os.path.join(inner_llvip, 'Annotations')
    
    if not os.path.exists(ir_images_path):
        print(f"Warning: Infrared images not found at {ir_images_path}")
        return
    
    if not os.path.exists(annotations_path):
        print(f"Warning: Annotations not found at {annotations_path}")
        return
    
    print(f"Processing LLVIP {split_name} split (using infrared images)...")
    
    # Get class mapping
    llvip_to_yolo_classes = get_llvip_class_mapping()
    
    # Map test to val for consistency with other datasets
    output_split = 'val' if split_name == 'test' else split_name
    
    # Output paths - add to existing main_dataset
    output_images_path = os.path.join(output_base_path, 'main_dataset', output_split, 'images')
    output_labels_path = os.path.join(output_base_path, 'main_dataset', output_split, 'labels')
    
    # Ensure directories exist
    os.makedirs(output_images_path, exist_ok=True)
    os.makedirs(output_labels_path, exist_ok=True)
    
    # Get all infrared images
    image_files = [f for f in os.listdir(ir_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    processed_count = 0
    skipped_count = 0
    coordinate_errors = 0
    
    for image_filename in image_files:
        image_path = os.path.join(ir_images_path, image_filename)
        
        # Find corresponding annotation file
        base_name = os.path.splitext(image_filename)[0]
        annotation_file = os.path.join(annotations_path, base_name + '.xml')
        
        if not os.path.exists(annotation_file):
            print(f"Warning: No annotation found for {image_filename}")
            skipped_count += 1
            continue
        
        # Load original image to get ORIGINAL dimensions (CRITICAL!)
        original_image = cv2.imread(image_path)
        if original_image is None:
            print(f"Warning: Could not load image {image_path}")
            skipped_count += 1
            continue
        
        # Get ORIGINAL dimensions before any resizing
        original_height, original_width = original_image.shape[:2]
        
        # Create unique filename
        clean_filename = os.path.basename(image_filename)
        base_name = os.path.splitext(clean_filename)[0]
        extension = os.path.splitext(clean_filename)[1]
        unique_filename = f"llvip_{output_split}_{base_name}{extension}"
        
        # Parse annotations using ORIGINAL dimensions
        filename, width, height, objects = parse_llvip_xml_CORRECTED(annotation_file)
        
        # Process annotations
        yolo_annotations = []
        for obj in objects:
            class_name = obj['name'].lower()
            if class_name in llvip_to_yolo_classes:
                yolo_class_id = llvip_to_yolo_classes[class_name]
                
                # Convert bbox to YOLO format using ORIGINAL image dimensions
                yolo_bbox = voc_to_yolo_bbox_CORRECTED(obj['bbox'], original_width, original_height)
                
                # Validate the converted bbox
                x_center, y_center, bbox_width, bbox_height = yolo_bbox
                if (0 <= x_center <= 1 and 0 <= y_center <= 1 and 
                    0 < bbox_width <= 1 and 0 < bbox_height <= 1):
                    yolo_annotations.append([yolo_class_id] + yolo_bbox)
                else:
                    coordinate_errors += 1
                    print(f"Warning: Invalid coordinates in {image_filename}: {yolo_bbox}")
        
        # NOW resize the image (after bbox conversion)
        resized_image = cv2.resize(original_image, target_size)
        
        # Save resized image
        output_image_path = os.path.join(output_images_path, unique_filename)
        cv2.imwrite(output_image_path, resized_image)
        
        # Save YOLO format label file
        label_filename = os.path.splitext(unique_filename)[0] + '.txt'
        label_path = os.path.join(output_labels_path, label_filename)
        
        with open(label_path, 'w') as f:
            for annotation in yolo_annotations:
                class_id, x_center, y_center, width, height = annotation
                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
        
        processed_count += 1
        if processed_count % 100 == 0:
            print(f"  Processed {processed_count} images...")
    
    print(f"  Completed LLVIP {split_name}: {processed_count} images processed, {skipped_count} skipped")
    if coordinate_errors > 0:
        print(f"  Warning: {coordinate_errors} coordinate errors found")

def update_dataset_yaml_with_llvip(base_path):
    """Update the main dataset YAML file to include LLVIP data"""
    yaml_path = os.path.join(base_path, 'main_dataset', 'data.yaml')
    
    # Updated class names including LLVIP classes
    class_names = [
        'person',         # 0 (includes LLVIP person, people, pedestrian, human, man, woman, child)
        'bicycle',        # 1 (includes LLVIP bicycle, bike)
        'car',           # 2 (includes LLVIP car, vehicle)
        'motorcycle',    # 3
        'bus',           # 4
        'truck',         # 5
        'dog',           # 6
        'skateboard',    # 7
        'other_vehicle'  # 8
    ]
    
    yaml_content = f"""# Combined Thermal Dataset Configuration (FLIR + SMOD + IR_det + KAIST + LLVIP) - CORRECTED
path: {os.path.abspath(os.path.join(base_path, 'main_dataset'))}
train: train/images
val: val/images
test: test/images

# Number of classes
nc: {len(class_names)}

# Class names
names: {class_names}

# Sources: FLIR_ADAS_v2, SMOD, IR_det, KAIST, LLVIP
# Processing: CORRECTED coordinate normalization using original image dimensions
"""
    
    with open(yaml_path, 'w') as f:
        f.write(yaml_content)
    
    print(f"Updated data.yaml with LLVIP classes at {yaml_path}")

def validate_llvip_annotations(base_path, num_samples=5):
    """Validate LLVIP annotations to ensure they look correct"""
    print(f"\nüîç VALIDATING LLVIP ANNOTATIONS")
    print("=" * 50)
    
    train_labels_path = os.path.join(base_path, 'main_dataset', 'train', 'labels')
    if not os.path.exists(train_labels_path):
        print("No training labels found for validation")
        return
    
    # Look specifically for LLVIP files
    llvip_files = [f for f in os.listdir(train_labels_path) if f.startswith('llvip_')][:num_samples]
    
    if not llvip_files:
        print("No LLVIP files found for validation")
        return
    
    for label_file in llvip_files:
        label_path = os.path.join(train_labels_path, label_file)
        print(f"\nüìÑ {label_file}:")
        
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
            
            valid_count = 0
            invalid_count = 0
            class_distribution = {}
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    try:
                        class_id = int(parts[0])
                        x, y, w, h = map(float, parts[1:5])
                        
                        # Track class distribution
                        class_distribution[class_id] = class_distribution.get(class_id, 0) + 1
                        
                        # Check if coordinates are in valid range
                        if (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):
                            valid_count += 1
                        else:
                            invalid_count += 1
                            print(f"   ‚ö†Ô∏è  Invalid: class={class_id}, x={x:.3f}, y={y:.3f}, w={w:.3f}, h={h:.3f}")
                    except ValueError:
                        invalid_count += 1
            
            print(f"   ‚úÖ Valid annotations: {valid_count}")
            print(f"   üéØ Classes found: {class_distribution}")
            if invalid_count > 0:
                print(f"   ‚ùå Invalid annotations: {invalid_count}")
            else:
                print(f"   üéØ All LLVIP coordinates properly normalized!")
                
        except Exception as e:
            print(f"   Error reading file: {e}")

def main():
    # Set paths
    base_path = r"D:\datasets"
    llvip_path = os.path.join(base_path, "LLVIP")
    
    # Verify LLVIP dataset exists
    if not os.path.exists(llvip_path):
        print(f"Error: LLVIP dataset not found at {llvip_path}")
        return
    
    print("üöÄ STARTING CORRECTED LLVIP PREPROCESSING")
    print("=" * 60)
    print(f"Source: {llvip_path}")
    print(f"Output: Adding to existing main_dataset")
    print("üîß CORRECTION: Using original image dimensions for bbox normalization")
    print("üå°Ô∏è  Using infrared images - low-light person detection specialist")
    print("üåô Focus: Dark scene pedestrian detection where thermal excels")
    print("=" * 60)
    
    # Check if main_dataset exists
    main_dataset_path = os.path.join(base_path, 'main_dataset')
    if not os.path.exists(main_dataset_path):
        print("Warning: main_dataset folder doesn't exist. Run FLIR preprocessing first.")
        return
    
    # Process train and test splits
    splits = ['train', 'test']
    for split in splits:
        process_llvip_split_CORRECTED(llvip_path, base_path, split, target_size=(640, 512))
    
    # Update dataset configuration
    update_dataset_yaml_with_llvip(base_path)
    
    # Validate sample annotations
    validate_llvip_annotations(base_path)
    
    print("\n‚úÖ CORRECTED LLVIP preprocessing completed!")
    print("üìä Summary:")
    print("   - ~15,488 infrared images focused on low-light person detection")
    print("   - Pascal VOC XML annotations converted to YOLO format")
    print("   - Bounding boxes normalized using ORIGINAL image dimensions")
    print("   - Specialized for dark scenes where thermal imaging excels")
    print("   - All coordinates should now be in valid [0,1] range")
    print("\nReady for next dataset!")

if __name__ == "__main__":
    main()
